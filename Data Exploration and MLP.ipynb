{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f19c74f-d4bc-413f-b51c-a6b7cb723f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "\u001b[K     |████████████████████████████████| 292 kB 21.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.22.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.8/site-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.6.3)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (3.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (4.29.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (9.0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.11.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37bb5304-b3e5-4cd5-8d75-766251ec6129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting contractions\n",
      "  Downloading contractions-0.1.72-py2.py3-none-any.whl (8.3 kB)\n",
      "Collecting textsearch>=0.0.21\n",
      "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting pyahocorasick\n",
      "  Downloading pyahocorasick-1.4.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (110 kB)\n",
      "\u001b[K     |████████████████████████████████| 110 kB 24.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting anyascii\n",
      "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
      "\u001b[K     |████████████████████████████████| 287 kB 27.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.1 contractions-0.1.72 pyahocorasick-1.4.4 textsearch-0.0.21\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e88ad6fd-058b-4eb8-a1a3-44dce8c1f066",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"data/train_14k_split_conll.txt\"\n",
    "test_file = \"data/dev_3k_split_conll.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42d392c3-af26-4dbc-9489-5911d221cb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.12.18-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 22.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.5.12-py2.py3-none-any.whl (145 kB)\n",
      "\u001b[K     |████████████████████████████████| 145 kB 29.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf<4.0dev,>=3.12.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (3.19.4)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from wandb) (5.4.1)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.26.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (5.9.0)\n",
      "Collecting setproctitle\n",
      "  Downloading setproctitle-1.2.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.16.0)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
      "\u001b[K     |████████████████████████████████| 181 kB 26.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting promise<3,>=2.0\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from wandb) (59.5.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (8.0.3)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 37.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.26.7)\n",
      "Building wheels for collected packages: promise, pathtools\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21503 sha256=c80dd883808464f598e355a6fce31259bfae5c1d8882c632d3aafa0878c3ae29\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-dec7cr2e/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=e0b1449464d2ca5ce1a0ce7ec4d2a9f807ab52d2a4ff5f04c2f9da03b0efaa72\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-dec7cr2e/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
      "Successfully built promise pathtools\n",
      "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, promise, pathtools, GitPython, docker-pycreds, wandb\n",
      "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 promise-2.3 sentry-sdk-1.5.12 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 wandb-0.12.18\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d8b613d-8a02-4711-91d3-c844f339e80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import string\n",
    "import contractions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import wandb\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2919d17-5b8c-461b-8224-be1554d5aa85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e61f625-5860-41a2-8675-6ff2be694e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "660f8c7b-d2ba-46e4-b7fc-e7b76c01845a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1wa5zyfu) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ruby-fog-1</strong>: <a href=\"https://wandb.ai/alokpadhi/Sentiment%20Analysis-Hinglish/runs/1wa5zyfu\" target=\"_blank\">https://wandb.ai/alokpadhi/Sentiment%20Analysis-Hinglish/runs/1wa5zyfu</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220619_173514-1wa5zyfu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1wa5zyfu). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20220619_173543-3rxv0ijv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/alokpadhi/Sentiment%20Analysis-Hinglish/runs/3rxv0ijv\" target=\"_blank\">fanciful-durian-2</a></strong> to <a href=\"https://wandb.ai/alokpadhi/Sentiment%20Analysis-Hinglish\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./data)... Done. 0.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_artifacts.Artifact at 0x7f6b460d60d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = wandb.init(project=\"Sentiment Analysis-Hinglish\", entity=\"alokpadhi\")\n",
    "raw_data = wandb.Artifact(\"Train-Test-Data\", type=\"raw_data\")\n",
    "raw_data.add_dir(Path(\"data/\"))\n",
    "run.log_artifact(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eee69778-1e7a-43ad-90b2-e3a970cd9b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the files\n",
    "with open(train_file) as f:\n",
    "    train_data = f.readlines()\n",
    "    \n",
    "with open(test_file, 'r') as f:\n",
    "    test_data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d48c5ce-8e21-4ab7-ac3d-aa707b4e15ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29c41af2-7a88-4229-a413-b7173a295fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bhai\\tHin\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data\n",
    "train_data[random.randint(0, len(train_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0bfaedca-e49a-4fcf-bdb7-5b9abc1f0995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meta\\t4330\\tneutral\\n',\n",
       " 'nen\\tEng\\n',\n",
       " 'á\\tO\\n',\n",
       " 'vist\\tEng\\n',\n",
       " 'bolest\\tEng\\n',\n",
       " 'vztek\\tEng\\n',\n",
       " 'smutek\\tEng\\n',\n",
       " 'zmatek\\tHin\\n',\n",
       " 'osam\\tHin\\n',\n",
       " 'ě\\tO\\n',\n",
       " 'lost\\tEng\\n',\n",
       " 'beznad\\tEng\\n',\n",
       " 'ě\\tO\\n',\n",
       " 'j\\tHin\\n',\n",
       " 'a\\tEng\\n',\n",
       " 'nakonec\\tEng\\n',\n",
       " 'jen\\tHin\\n',\n",
       " 'klid\\tHin\\n',\n",
       " 'Asi\\tHin\\n',\n",
       " 'takhle\\tHin\\n',\n",
       " 'vypad\\tHin\\n',\n",
       " 'á\\tO\\n',\n",
       " 'm\\tHin\\n',\n",
       " 'ů\\tO\\n',\n",
       " 'j\\tEng\\n',\n",
       " 'life\\tEng\\n',\n",
       " '...\\tO\\n',\n",
       " '\\n',\n",
       " 'meta\\t41616\\tneutral\\n',\n",
       " '@\\tO\\n']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29ec5343-5282-4c97-87c2-eb8690377545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the data\n",
    "def parse_data(data):\n",
    "    sentences, sentences_info, sentiment = [], [], []\n",
    "    all_langs = []\n",
    "    \n",
    "    single_sentence, single_sentence_info = [], []\n",
    "    sent = \"\"\n",
    "    \n",
    "    for i, line in enumerate(data):\n",
    "        line_ = line.strip()\n",
    "        tokens = line_.split('\\t')\n",
    "        num_tokens = len(tokens)\n",
    "        if num_tokens == 2:\n",
    "            # add the word\n",
    "            single_sentence.append(tokens[0])\n",
    "            # add the language\n",
    "            single_sentence_info.append(tokens[1])\n",
    "            all_langs.append(tokens[1])\n",
    "        elif num_tokens == 3 and i > 0:\n",
    "            sentences.append(single_sentence)\n",
    "            sentences_info.append(single_sentence_info)\n",
    "            sentiment.append(sent)\n",
    "            sent = tokens[-1]\n",
    "            single_sentence = []\n",
    "            single_sentence_info = []\n",
    "        elif num_tokens == 1:\n",
    "            continue\n",
    "        else:\n",
    "            sent = tokens[-1]\n",
    "            \n",
    "    if len(single_sentence) > 0:\n",
    "        sentences.append(single_sentence)\n",
    "        sentences_info.append(single_sentence_info)\n",
    "        sentiment.append(sent)\n",
    "        \n",
    "    assert len(sentences) == len(sentences_info) == len(sentiment)\n",
    "    return sentences, sentences_info, sentiment, all_langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e5966ed-8a47-4b18-a54c-427aa4cf123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, sentences_info, sentiment, all_langs = parse_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f36ca318-7ef5-408f-92d8-9627e642ef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences, test_sentences_info, test_sentiment, test_all_langs = parse_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61e9166a-ee3e-470d-83c3-5700afaeedf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44aca097-adbf-4f4c-9de8-09410be174ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Language count plot\n",
    "sns.countplot(all_langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dcf65d3e-5e44-47f1-8e72-450b5872afdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sentiment count plot\n",
    "sns.countplot(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98ecc408-3521-4ddb-9fd5-cedff2c5dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_lengths = [len(sent) for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aca097f3-f680-4cab-8828-b4a4da9ea072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sentence length distrubution\n",
    "plt.figure(figsize=(15,9))\n",
    "sns.countplot(token_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2065b90e-37da-4b51-8828-d4dba971998a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nen',\n",
       " 'á',\n",
       " 'vist',\n",
       " 'bolest',\n",
       " 'vztek',\n",
       " 'smutek',\n",
       " 'zmatek',\n",
       " 'osam',\n",
       " 'ě',\n",
       " 'lost',\n",
       " 'beznad',\n",
       " 'ě',\n",
       " 'j',\n",
       " 'a',\n",
       " 'nakonec',\n",
       " 'jen',\n",
       " 'klid',\n",
       " 'Asi',\n",
       " 'takhle',\n",
       " 'vypad',\n",
       " 'á',\n",
       " 'm',\n",
       " 'ů',\n",
       " 'j',\n",
       " 'life',\n",
       " '...']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e963abe9-6af9-4f9a-91c2-922e2162dc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = re.sub(\"\\sRT\\s\", \"\", \"test RT \")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9fd3c927-941e-4f97-b2cf-5148401157bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "url_pattern = r'https(.*)/\\s\\w+'\n",
    "names_with_numbers = r'([A-Za-z]+)\\d{3,}'\n",
    "apostee = r\"([\\w]+)\\s'\\s([\\w]+)\"\n",
    "names = r\"@[\\s]*[\\w]+[\\s]*[_]+[\\s]*[\\w]+|@[\\s]*[\\w]+\"\n",
    "\n",
    "def preprocess_data(sentence_tokens):\n",
    "    sentence = \" \".join(sentence_tokens)\n",
    "    sentence = \" \" + sentence\n",
    "    \n",
    "    # Remove RT and ...\n",
    "    sentence = re.sub(\"\\sRT\\s\", \"\", sentence)\n",
    "    sentence = sentence.replace(\"…\", \"\")\n",
    "    sentence = re.sub(re.compile(names), \" \", sentence)\n",
    "    sentence = re.sub(re.compile(url_pattern), \"\", sentence)\n",
    "    sentence = re.sub(re.compile(apostee), r\"\\1'\\2\", sentence)\n",
    "    \n",
    "    # fixing contractions\n",
    "    sentence = contractions.fix(sentence)\n",
    "    \n",
    "    sentence = re.sub(re.compile(names_with_numbers), r\" \", sentence)\n",
    "    \n",
    "    sentence = \" \".join(sentence.split()).strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "64754105-200f-4b70-8dd4-dadad64ce690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@ nehantics Haan yaar neha 😔😔 kab karega woh post 😭 Usne na sach mein photoshoot karna chahiye phir woh post karega … https // tco / 5RSlSbZNtt'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bcf455a5-58f6-4c9a-8b58-6a7d60cc3d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Haan yaar neha 😔😔 kab karega woh post 😭 Usne na sach mein photoshoot karna chahiye phir woh post karega'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_data(sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f8c7b7d9-86e0-432f-9072-47af62527a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess all training samples\n",
    "processed_sentences = []\n",
    "for sent in sentences:\n",
    "    processed_sentences.append(preprocess_data(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4e45a683-f2db-40d2-992e-a3f44fba1c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processed_sentences = []\n",
    "for sent in test_sentences:\n",
    "    test_processed_sentences.append(preprocess_data(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "76f010ee-ddf8-4f1b-9b7b-12130f401d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_mapping = {\n",
    "    \"positive\": 0,\n",
    "    \"negative\": 1,\n",
    "    \"neutral\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bb81b5e1-b234-4b43-ade8-12b46e4e168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [sentiment_mapping[sent] for sent in sentiment]\n",
    "test_labels = [sentiment_mapping[sent] for sent in test_sentiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d5971574-e7b9-4940-9224-1d10251ef4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test dataframe with processed data for future use\n",
    "assert len(processed_sentences) == len(labels) == len(sentiment)\n",
    "train_dataset = list(zip(processed_sentences, sentiment, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "86705daa-8de1-49b3-b1d2-9adcf47af16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_dataset, columns=[\"Sentence\", \"Sentiment\", \"Sentence Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "37d2c686-d00c-4728-a36e-f4d710274b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentence Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nen á vist bolest vztek smutek zmatek osam ě l...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haan yaar neha 😔😔 kab karega woh post 😭 Usne n...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>television media congress ke liye nhi h . Ye t...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All India me nrc lagu kare w Kashmir se dhara ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pagal hai kya ? They aren ’ t real issues Mand...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment  Sentence Label\n",
       "0  nen á vist bolest vztek smutek zmatek osam ě l...   neutral               2\n",
       "1  Haan yaar neha 😔😔 kab karega woh post 😭 Usne n...   neutral               2\n",
       "2  television media congress ke liye nhi h . Ye t...  negative               1\n",
       "3  All India me nrc lagu kare w Kashmir se dhara ...  positive               0\n",
       "4  Pagal hai kya ? They aren ’ t real issues Mand...   neutral               2"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ffbf6ea0-d168-4b98-b227-6977bd8d7bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentence Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modi mantrimandal may samil honay par badhai n...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tu toh naamakool hai Mare h</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YOU saw caste and religion in them ... nation ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sir local police station pe complaint krne par...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ve Maahi song from # Kesari is current favouri...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment  Sentence Label\n",
       "0  modi mantrimandal may samil honay par badhai n...  positive               0\n",
       "1                        Tu toh naamakool hai Mare h  negative               1\n",
       "2  YOU saw caste and religion in them ... nation ...  negative               1\n",
       "3  sir local police station pe complaint krne par...   neutral               2\n",
       "4  Ve Maahi song from # Kesari is current favouri...  positive               0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create train and test dataframe with processed data for future use\n",
    "assert len(test_processed_sentences) == len(test_labels) == len(test_sentiment)\n",
    "test_dataset = list(zip(test_processed_sentences, test_sentiment, test_labels))\n",
    "\n",
    "test_df = pd.DataFrame(test_dataset, columns=[\"Sentence\", \"Sentiment\", \"Sentence Label\"])\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7c33dfd6-92be-482f-8488-a5be048a1a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"Process Train Dataframe\": wandb.Table(data=train_dataset, columns=[\"Sentence\", \"Sentiment\", \"Sentiment Label\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ab923268-d48f-43ae-9ea5-4305fbe8ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"Process Test Dataframe\": wandb.Table(data=test_dataset, columns=[\"Sentence\", \"Sentiment\", \"Sentiment Label\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e0cac1a2-776f-42da-b1c6-6da9dfa7ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, train_label, val_label = train_test_split(processed_sentences, labels, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ad263ed9-85a4-40ef-b609-edb27c5dd71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample size: 10500\n",
      " Validation sample size: 3500\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training sample size: {len(train_data)}\\n Validation sample size: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b3fa3a70-9f8c-4f79-8400-dd5a5ba0038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the token vocab\n",
    "counter = Counter()\n",
    "for line in train_data:\n",
    "    tokens = line.strip().split()\n",
    "    counter.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cdcfe239-c947-4bf1-9bd3-ca1246c39346",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "for key in counter.most_common():\n",
    "    if key[1] > 15:\n",
    "        vocab.append(key[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "da25361f-8673-4cd7-8121-423a5523af72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1466"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "09c8b180-64cb-4373-9734-ef8bf70cd970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'hai', 'ki', 'to', 'ko']\n"
     ]
    }
   ],
   "source": [
    "print(vocab[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4490a744-ecfa-45f7-a5ce-d30c86a51538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "318c13cd-3973-4d3a-96e2-fc8eafffb426",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "9b76ae96-4ca2-4a0c-bf94-e64474dafe4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mujhe to nahi lagta koi darta hai . ye hi log hain jo Desh k logo ko darne or darane ki ra'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "94d0d684-ba7d-490d-b5c6-f01daf49ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = vectorizer.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "498fa8d0-4847-4cad-8000-c66254d7f802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1331)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a6e785b2-01f2-481b-bdbb-8d86e9e4a610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10500, 1331)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "3803bf3f-b1ba-4c7a-9cf0-bf80f6e38e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10500, 1331])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input = torch.FloatTensor(train_X.toarray())\n",
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b7755caf-eff9-43d2-b1a7-76daca0070f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1331])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "86c99794-ada3-4d3b-bad9-22feea02096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = torch.FloatTensor(vectorizer.transform(val_data).toarray())\n",
    "test_X = torch.FloatTensor(vectorizer.transform(test_data).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "fed863e1-6898-4310-9564-6a9fff610707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch dataset\n",
    "class HinglishDataset(Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return [self.inputs[idx], self.labels[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "8ff8e321-c277-407a-8ef5-2cd8f598c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HinglishDataset(train_input, train_label)\n",
    "val_dataset = HinglishDataset(val_X, val_label)\n",
    "test_dataset = HinglishDataset(test_X, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f26cbe97-45f9-4ff0-852e-408845480463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1331])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d664d5de-f501-4d8e-83c8-faf7cee2386b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1331])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "20136586-4d46-4e7a-8f39-705478ebb458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1331])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9dc64234-3262-46a8-acdd-51e89bbf350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(vectorizer.get_feature_names())\n",
    "output_dim = 3\n",
    "hidden1_dim = 256\n",
    "hidden2_dim = 128\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "143ca87c-5a93-4515-b3bf-9d49e061ec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "8a59e3bd-8a8e-4413-8dcd-a64885ec5234",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(input_dim, hidden1_dim),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden1_dim, hidden2_dim),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden2_dim, output_dim),\n",
    "    nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "a1eb7d76-665d-46da-bad6-b329ab7cca8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1331, out_features=256, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=128, out_features=3, bias=True)\n",
       "  (5): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "8d28a161-4b01-4401-927a-e3eaa810c83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "7c13ed7c-5fcc-4e28-9028-09d00891e9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, )\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f27c2c79-8e84-496c-8e0e-0da63a74f581",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "71915ea2-785b-4046-bac6-936600d7bd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1331])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "38eb407a-c0af-4a93-9ffd-eba38bf91764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "12341917-b378-4f4d-8d4b-f9bd46b6c1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(iterator):\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    train_example_ct = 0  # number of examples seen\n",
    "    train_batch_ct = 0\n",
    "    \n",
    "    for batch in iterator:\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = batch\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs.to(device))\n",
    "        \n",
    "        train_example_ct +=  len(inputs)\n",
    "        train_batch_ct += 1\n",
    "        \n",
    "        loss = criterion(outputs, labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step(loss)\n",
    "        \n",
    "        if ((train_batch_ct + 1) % 15) == 0:\n",
    "            print(f\"Training Loss after \" + str(train_example_ct).zfill(5) + f\" examples: {loss:.3f}\")\n",
    "            wandb.log({\"training_loss\": loss}, step=train_example_ct)\n",
    "            \n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "2b182d4b-4ce0-48e0-bd56-696240d6a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_accuracy(preds, labels):\n",
    "    \"\"\"Takes in two lists of predicted labels and actual labels and returns the accuracy in the form of a float. \"\"\"\n",
    "    return np.equal(preds, labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "847a88d9-d820-490b-9041-d4c154c697b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(iterator):\n",
    "    epoch_loss = 0\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    trgs = []\n",
    "    \n",
    "    valid_example_ct = 0  # number of examples seen\n",
    "    valid_batch_ct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = batch\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs.to(device))\n",
    "            \n",
    "            valid_example_ct +=  len(inputs)\n",
    "            valid_batch_ct += 1\n",
    "            \n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            trgs.extend(labels.numpy().tolist())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            preds.extend(predicted.cpu().numpy().tolist())\n",
    "            \n",
    "            # Report metrics every 15th batch\n",
    "            if ((valid_batch_ct + 1) % 15) == 0:\n",
    "                print(f\"Loss after (validating)\" + str(valid_example_ct).zfill(5) + f\" examples: {loss:.3f}\")\n",
    "                wandb.log({\"validation_loss\": loss}, step=valid_example_ct)\n",
    "    \n",
    "    return epoch_loss / len(iterator), simple_accuracy(preds, trgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "108cff76-a542-4a93-b5bf-46c9c119e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = elapsed_time - (elapsed_mins * 60)\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "70ac95d6-43aa-4a30-b2e0-b0f904450f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(\"model/\")\n",
    "model_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "621b44bb-0afc-47a5-84cd-169ce8655543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20220619_204531-188r2anu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/alokpadhi/Sentiment%20Analysis-Hinglish/runs/188r2anu\" target=\"_blank\">amber-puddle-14</a></strong> to <a href=\"https://wandb.ai/alokpadhi/Sentiment%20Analysis-Hinglish\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss after 00896 examples: 1.101\n",
      "Training Loss after 01856 examples: 1.096\n",
      "Training Loss after 02816 examples: 1.095\n",
      "Training Loss after 03776 examples: 1.096\n",
      "Training Loss after 04736 examples: 1.099\n",
      "Training Loss after 05696 examples: 1.098\n",
      "Training Loss after 06656 examples: 1.099\n",
      "Training Loss after 07616 examples: 1.099\n",
      "Training Loss after 08576 examples: 1.093\n",
      "Training Loss after 09536 examples: 1.098\n",
      "Training Loss after 10496 examples: 1.092\n",
      "Loss after (validating)00896 examples: 1.096\n",
      "Loss after (validating)01856 examples: 1.091\n",
      "Loss after (validating)02816 examples: 1.101\n",
      "Epoch: 01 | Time: 0m 3.96s\n",
      "\tTrain Loss: 1.097 | Val Loss: 1.097 | Val Acc: 0.378\n",
      "Training Loss after 00896 examples: 1.098\n",
      "Training Loss after 01856 examples: 1.095\n",
      "Training Loss after 02816 examples: 1.096\n",
      "Training Loss after 03776 examples: 1.099\n",
      "Training Loss after 04736 examples: 1.091\n",
      "Training Loss after 05696 examples: 1.096\n",
      "Training Loss after 06656 examples: 1.093\n",
      "Training Loss after 07616 examples: 1.099\n",
      "Training Loss after 08576 examples: 1.095\n",
      "Training Loss after 09536 examples: 1.095\n",
      "Training Loss after 10496 examples: 1.094\n",
      "Loss after (validating)00896 examples: 1.095\n",
      "Loss after (validating)01856 examples: 1.090\n",
      "Loss after (validating)02816 examples: 1.100\n",
      "Epoch: 02 | Time: 0m 3.98s\n",
      "\tTrain Loss: 1.096 | Val Loss: 1.096 | Val Acc: 0.378\n",
      "Training Loss after 00896 examples: 1.094\n",
      "Training Loss after 01856 examples: 1.101\n",
      "Training Loss after 02816 examples: 1.097\n",
      "Training Loss after 03776 examples: 1.102\n",
      "Training Loss after 04736 examples: 1.093\n",
      "Training Loss after 05696 examples: 1.100\n",
      "Training Loss after 06656 examples: 1.093\n",
      "Training Loss after 07616 examples: 1.098\n",
      "Training Loss after 08576 examples: 1.098\n",
      "Training Loss after 09536 examples: 1.096\n",
      "Training Loss after 10496 examples: 1.095\n",
      "Loss after (validating)00896 examples: 1.095\n",
      "Loss after (validating)01856 examples: 1.088\n",
      "Loss after (validating)02816 examples: 1.099\n",
      "Epoch: 03 | Time: 0m 4.21s\n",
      "\tTrain Loss: 1.096 | Val Loss: 1.095 | Val Acc: 0.378\n",
      "Training Loss after 00896 examples: 1.100\n",
      "Training Loss after 01856 examples: 1.092\n",
      "Training Loss after 02816 examples: 1.104\n",
      "Training Loss after 03776 examples: 1.104\n",
      "Training Loss after 04736 examples: 1.097\n",
      "Training Loss after 05696 examples: 1.090\n",
      "Training Loss after 06656 examples: 1.099\n",
      "Training Loss after 07616 examples: 1.092\n",
      "Training Loss after 08576 examples: 1.095\n",
      "Training Loss after 09536 examples: 1.088\n",
      "Training Loss after 10496 examples: 1.099\n",
      "Loss after (validating)00896 examples: 1.094\n",
      "Loss after (validating)01856 examples: 1.087\n",
      "Loss after (validating)02816 examples: 1.099\n",
      "Epoch: 04 | Time: 0m 4.15s\n",
      "\tTrain Loss: 1.095 | Val Loss: 1.095 | Val Acc: 0.378\n",
      "Training Loss after 00896 examples: 1.101\n",
      "Training Loss after 01856 examples: 1.097\n",
      "Training Loss after 02816 examples: 1.095\n",
      "Training Loss after 03776 examples: 1.090\n",
      "Training Loss after 04736 examples: 1.100\n",
      "Training Loss after 05696 examples: 1.092\n",
      "Training Loss after 06656 examples: 1.096\n",
      "Training Loss after 07616 examples: 1.093\n",
      "Training Loss after 08576 examples: 1.089\n",
      "Training Loss after 09536 examples: 1.090\n",
      "Training Loss after 10496 examples: 1.098\n",
      "Loss after (validating)00896 examples: 1.094\n",
      "Loss after (validating)01856 examples: 1.085\n",
      "Loss after (validating)02816 examples: 1.098\n",
      "Epoch: 05 | Time: 0m 3.67s\n",
      "\tTrain Loss: 1.095 | Val Loss: 1.095 | Val Acc: 0.378\n",
      "Training Loss after 00896 examples: 1.104\n",
      "Training Loss after 01856 examples: 1.093\n",
      "Training Loss after 02816 examples: 1.089\n",
      "Training Loss after 03776 examples: 1.096\n",
      "Training Loss after 04736 examples: 1.094\n",
      "Training Loss after 05696 examples: 1.093\n",
      "Training Loss after 06656 examples: 1.108\n",
      "Training Loss after 07616 examples: 1.096\n",
      "Training Loss after 08576 examples: 1.080\n",
      "Training Loss after 09536 examples: 1.087\n",
      "Training Loss after 10496 examples: 1.089\n",
      "Loss after (validating)00896 examples: 1.093\n",
      "Loss after (validating)01856 examples: 1.084\n",
      "Loss after (validating)02816 examples: 1.097\n",
      "Epoch: 06 | Time: 0m 3.87s\n",
      "\tTrain Loss: 1.094 | Val Loss: 1.094 | Val Acc: 0.378\n",
      "Training Loss after 00896 examples: 1.092\n",
      "Training Loss after 01856 examples: 1.092\n",
      "Training Loss after 02816 examples: 1.087\n",
      "Training Loss after 03776 examples: 1.100\n",
      "Training Loss after 04736 examples: 1.089\n",
      "Training Loss after 05696 examples: 1.090\n",
      "Training Loss after 06656 examples: 1.100\n",
      "Training Loss after 07616 examples: 1.085\n",
      "Training Loss after 08576 examples: 1.090\n",
      "Training Loss after 09536 examples: 1.102\n",
      "Training Loss after 10496 examples: 1.094\n",
      "Loss after (validating)00896 examples: 1.093\n",
      "Loss after (validating)01856 examples: 1.083\n",
      "Loss after (validating)02816 examples: 1.097\n",
      "Epoch: 07 | Time: 0m 4.23s\n",
      "\tTrain Loss: 1.094 | Val Loss: 1.094 | Val Acc: 0.378\n",
      "Training Loss after 00896 examples: 1.098\n",
      "Training Loss after 01856 examples: 1.084\n",
      "Training Loss after 02816 examples: 1.098\n",
      "Training Loss after 03776 examples: 1.099\n",
      "Training Loss after 04736 examples: 1.093\n",
      "Training Loss after 05696 examples: 1.089\n",
      "Training Loss after 06656 examples: 1.089\n",
      "Training Loss after 07616 examples: 1.101\n",
      "Training Loss after 08576 examples: 1.097\n",
      "Training Loss after 09536 examples: 1.088\n",
      "Training Loss after 10496 examples: 1.088\n",
      "Loss after (validating)00896 examples: 1.093\n",
      "Loss after (validating)01856 examples: 1.082\n",
      "Loss after (validating)02816 examples: 1.096\n",
      "Epoch: 08 | Time: 0m 4.16s\n",
      "\tTrain Loss: 1.094 | Val Loss: 1.094 | Val Acc: 0.378\n",
      "Training Loss after 00896 examples: 1.104\n",
      "Training Loss after 01856 examples: 1.090\n",
      "Training Loss after 02816 examples: 1.093\n",
      "Training Loss after 03776 examples: 1.099\n",
      "Training Loss after 04736 examples: 1.082\n",
      "Training Loss after 05696 examples: 1.089\n",
      "Training Loss after 06656 examples: 1.093\n",
      "Training Loss after 07616 examples: 1.081\n",
      "Training Loss after 08576 examples: 1.095\n",
      "Training Loss after 09536 examples: 1.078\n",
      "Training Loss after 10496 examples: 1.103\n",
      "Loss after (validating)00896 examples: 1.092\n",
      "Loss after (validating)01856 examples: 1.082\n",
      "Loss after (validating)02816 examples: 1.096\n",
      "Epoch: 09 | Time: 0m 4.04s\n",
      "\tTrain Loss: 1.094 | Val Loss: 1.093 | Val Acc: 0.378\n",
      "Training Loss after 00896 examples: 1.097\n",
      "Training Loss after 01856 examples: 1.094\n",
      "Training Loss after 02816 examples: 1.096\n",
      "Training Loss after 03776 examples: 1.096\n",
      "Training Loss after 04736 examples: 1.078\n",
      "Training Loss after 05696 examples: 1.083\n",
      "Training Loss after 06656 examples: 1.094\n",
      "Training Loss after 07616 examples: 1.098\n",
      "Training Loss after 08576 examples: 1.094\n",
      "Training Loss after 09536 examples: 1.081\n",
      "Training Loss after 10496 examples: 1.100\n",
      "Loss after (validating)00896 examples: 1.092\n",
      "Loss after (validating)01856 examples: 1.081\n",
      "Loss after (validating)02816 examples: 1.096\n",
      "Epoch: 10 | Time: 0m 4.32s\n",
      "\tTrain Loss: 1.094 | Val Loss: 1.093 | Val Acc: 0.378\n",
      "Training Loss after 00896 examples: 1.093\n",
      "Training Loss after 01856 examples: 1.095\n",
      "Training Loss after 02816 examples: 1.096\n",
      "Training Loss after 03776 examples: 1.098\n",
      "Training Loss after 04736 examples: 1.102\n",
      "Training Loss after 05696 examples: 1.090\n",
      "Training Loss after 06656 examples: 1.100\n",
      "Training Loss after 07616 examples: 1.091\n",
      "Training Loss after 08576 examples: 1.090\n",
      "Training Loss after 09536 examples: 1.085\n",
      "Training Loss after 10496 examples: 1.094\n",
      "Loss after (validating)00896 examples: 1.092\n",
      "Loss after (validating)01856 examples: 1.080\n",
      "Loss after (validating)02816 examples: 1.095\n",
      "Epoch: 11 | Time: 0m 4.31s\n",
      "\tTrain Loss: 1.093 | Val Loss: 1.093 | Val Acc: 0.378\n",
      "Training Loss after 00896 examples: 1.097\n",
      "Training Loss after 01856 examples: 1.093\n",
      "Training Loss after 02816 examples: 1.100\n",
      "Training Loss after 03776 examples: 1.100\n",
      "Training Loss after 04736 examples: 1.110\n",
      "Training Loss after 05696 examples: 1.102\n",
      "Training Loss after 06656 examples: 1.094\n",
      "Training Loss after 07616 examples: 1.099\n",
      "Training Loss after 08576 examples: 1.085\n",
      "Training Loss after 09536 examples: 1.095\n",
      "Training Loss after 10496 examples: 1.102\n",
      "Loss after (validating)00896 examples: 1.092\n",
      "Loss after (validating)01856 examples: 1.079\n",
      "Loss after (validating)02816 examples: 1.095\n",
      "Epoch: 12 | Time: 0m 3.86s\n",
      "\tTrain Loss: 1.093 | Val Loss: 1.092 | Val Acc: 0.378\n",
      "Training Loss after 00896 examples: 1.093\n",
      "Training Loss after 01856 examples: 1.105\n",
      "Training Loss after 02816 examples: 1.100\n",
      "Training Loss after 03776 examples: 1.098\n",
      "Training Loss after 04736 examples: 1.093\n",
      "Training Loss after 05696 examples: 1.100\n",
      "Training Loss after 06656 examples: 1.092\n",
      "Training Loss after 07616 examples: 1.100\n",
      "Training Loss after 08576 examples: 1.098\n",
      "Training Loss after 09536 examples: 1.113\n",
      "Training Loss after 10496 examples: 1.108\n",
      "Loss after (validating)00896 examples: 1.091\n",
      "Loss after (validating)01856 examples: 1.079\n",
      "Loss after (validating)02816 examples: 1.094\n",
      "Epoch: 13 | Time: 0m 3.96s\n",
      "\tTrain Loss: 1.093 | Val Loss: 1.092 | Val Acc: 0.378\n",
      "Training Loss after 00896 examples: 1.091\n",
      "Training Loss after 01856 examples: 1.087\n",
      "Training Loss after 02816 examples: 1.094\n",
      "Training Loss after 03776 examples: 1.081\n",
      "Training Loss after 04736 examples: 1.096\n",
      "Training Loss after 05696 examples: 1.074\n",
      "Training Loss after 06656 examples: 1.088\n",
      "Training Loss after 07616 examples: 1.090\n",
      "Training Loss after 08576 examples: 1.090\n",
      "Training Loss after 09536 examples: 1.098\n",
      "Training Loss after 10496 examples: 1.086\n",
      "Loss after (validating)00896 examples: 1.091\n",
      "Loss after (validating)01856 examples: 1.078\n",
      "Loss after (validating)02816 examples: 1.094\n",
      "Epoch: 14 | Time: 0m 4.02s\n",
      "\tTrain Loss: 1.093 | Val Loss: 1.092 | Val Acc: 0.378\n",
      "Training Loss after 00896 examples: 1.101\n",
      "Training Loss after 01856 examples: 1.077\n",
      "Training Loss after 02816 examples: 1.080\n",
      "Training Loss after 03776 examples: 1.096\n",
      "Training Loss after 04736 examples: 1.101\n",
      "Training Loss after 05696 examples: 1.095\n",
      "Training Loss after 06656 examples: 1.081\n",
      "Training Loss after 07616 examples: 1.106\n",
      "Training Loss after 08576 examples: 1.098\n",
      "Training Loss after 09536 examples: 1.103\n",
      "Training Loss after 10496 examples: 1.084\n",
      "Loss after (validating)00896 examples: 1.091\n",
      "Loss after (validating)01856 examples: 1.077\n",
      "Loss after (validating)02816 examples: 1.093\n",
      "Epoch: 15 | Time: 0m 3.93s\n",
      "\tTrain Loss: 1.093 | Val Loss: 1.092 | Val Acc: 0.378\n",
      "Training Loss after 00896 examples: 1.098\n",
      "Training Loss after 01856 examples: 1.099\n",
      "Training Loss after 02816 examples: 1.088\n",
      "Training Loss after 03776 examples: 1.099\n",
      "Training Loss after 04736 examples: 1.097\n",
      "Training Loss after 05696 examples: 1.107\n",
      "Training Loss after 06656 examples: 1.090\n",
      "Training Loss after 07616 examples: 1.097\n",
      "Training Loss after 08576 examples: 1.084\n",
      "Training Loss after 09536 examples: 1.093\n",
      "Training Loss after 10496 examples: 1.078\n",
      "Loss after (validating)00896 examples: 1.091\n",
      "Loss after (validating)01856 examples: 1.077\n",
      "Loss after (validating)02816 examples: 1.093\n",
      "Epoch: 16 | Time: 0m 4.27s\n",
      "\tTrain Loss: 1.093 | Val Loss: 1.092 | Val Acc: 0.378\n",
      "Training Loss after 00896 examples: 1.092\n",
      "Training Loss after 01856 examples: 1.102\n",
      "Training Loss after 02816 examples: 1.089\n",
      "Training Loss after 03776 examples: 1.100\n",
      "Training Loss after 04736 examples: 1.095\n",
      "Training Loss after 05696 examples: 1.109\n",
      "Training Loss after 06656 examples: 1.097\n",
      "Training Loss after 07616 examples: 1.098\n",
      "Training Loss after 08576 examples: 1.100\n",
      "Training Loss after 09536 examples: 1.104\n",
      "Training Loss after 10496 examples: 1.095\n",
      "Loss after (validating)00896 examples: 1.091\n",
      "Loss after (validating)01856 examples: 1.077\n",
      "Loss after (validating)02816 examples: 1.092\n",
      "Epoch: 17 | Time: 0m 3.78s\n",
      "\tTrain Loss: 1.092 | Val Loss: 1.091 | Val Acc: 0.378\n",
      "Training Loss after 00896 examples: 1.085\n",
      "Training Loss after 01856 examples: 1.087\n",
      "Training Loss after 02816 examples: 1.105\n",
      "Training Loss after 03776 examples: 1.091\n",
      "Training Loss after 04736 examples: 1.086\n",
      "Training Loss after 05696 examples: 1.091\n",
      "Training Loss after 06656 examples: 1.097\n",
      "Training Loss after 07616 examples: 1.081\n",
      "Training Loss after 08576 examples: 1.091\n",
      "Training Loss after 09536 examples: 1.078\n",
      "Training Loss after 10496 examples: 1.095\n",
      "Loss after (validating)00896 examples: 1.091\n",
      "Loss after (validating)01856 examples: 1.076\n",
      "Loss after (validating)02816 examples: 1.092\n",
      "Epoch: 18 | Time: 0m 3.95s\n",
      "\tTrain Loss: 1.092 | Val Loss: 1.091 | Val Acc: 0.378\n",
      "Training Loss after 00896 examples: 1.100\n",
      "Training Loss after 01856 examples: 1.101\n",
      "Training Loss after 02816 examples: 1.084\n",
      "Training Loss after 03776 examples: 1.102\n",
      "Training Loss after 04736 examples: 1.081\n",
      "Training Loss after 05696 examples: 1.073\n",
      "Training Loss after 06656 examples: 1.096\n",
      "Training Loss after 07616 examples: 1.085\n",
      "Training Loss after 08576 examples: 1.091\n",
      "Training Loss after 09536 examples: 1.099\n",
      "Training Loss after 10496 examples: 1.096\n",
      "Loss after (validating)00896 examples: 1.090\n",
      "Loss after (validating)01856 examples: 1.075\n",
      "Loss after (validating)02816 examples: 1.091\n",
      "Epoch: 19 | Time: 0m 4.59s\n",
      "\tTrain Loss: 1.092 | Val Loss: 1.091 | Val Acc: 0.378\n",
      "Training Loss after 00896 examples: 1.086\n",
      "Training Loss after 01856 examples: 1.090\n",
      "Training Loss after 02816 examples: 1.087\n",
      "Training Loss after 03776 examples: 1.097\n",
      "Training Loss after 04736 examples: 1.101\n",
      "Training Loss after 05696 examples: 1.102\n",
      "Training Loss after 06656 examples: 1.095\n",
      "Training Loss after 07616 examples: 1.077\n",
      "Training Loss after 08576 examples: 1.088\n",
      "Training Loss after 09536 examples: 1.069\n",
      "Training Loss after 10496 examples: 1.111\n",
      "Loss after (validating)00896 examples: 1.090\n",
      "Loss after (validating)01856 examples: 1.075\n",
      "Loss after (validating)02816 examples: 1.091\n",
      "Epoch: 20 | Time: 0m 4.63s\n",
      "\tTrain Loss: 1.092 | Val Loss: 1.091 | Val Acc: 0.378\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='28.592 MB of 28.592 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_loss</td><td>█▄▃▄▇▅▆▇▂▆▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>optimizer</td><td>SGD</td></tr><tr><td>training_loss</td><td>1.09236</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">amber-puddle-14</strong>: <a href=\"https://wandb.ai/alokpadhi/Sentiment%20Analysis-Hinglish/runs/188r2anu\" target=\"_blank\">https://wandb.ai/alokpadhi/Sentiment%20Analysis-Hinglish/runs/188r2anu</a><br/>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220619_204531-188r2anu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(project=\"Sentiment Analysis-Hinglish\") as run:\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "    \n",
    "    best_valid_loss = float('inf')\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        train_loss = train(train_loader)\n",
    "        val_loss, val_acc = evaluate(val_loader)\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        print(f\"Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs:.2f}s\")\n",
    "        print(f\"\\tTrain Loss: {train_loss:.3f} | Val Loss: {val_loss:.3f} | Val Acc: {val_acc:.3f}\")\n",
    "\n",
    "        if val_loss < best_valid_loss:\n",
    "            best_valid_loss = val_loss\n",
    "            torch.save(model.state_dict(), Path(model_path, \"multilayer_perceptron.pt\"))\n",
    "        \n",
    "        model_artifact = wandb.Artifact(\n",
    "          \"MLP\",type=\"model\",description=\"MLP baseline model\", metadata={\"hidden_layer_dims\": [256,128], \"activation\": \"ReLU\"})\n",
    "        \n",
    "        wandb.log({\"epoch\": epochs, \"optimizer\": \"SGD\"})\n",
    "        model_artifact.add_file(Path(model_path, \"multilayer_perceptron.pt\"))\n",
    "        run.log_artifact(model_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83998289-a765-4ab5-8709-b76065d2c7b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
